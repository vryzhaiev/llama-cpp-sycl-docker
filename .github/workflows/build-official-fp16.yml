name: Build and Publish official FP16

on:
  push:
    branches:
      - master
    paths:
      - '.github/workflows/build-official-fp16.yml'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Clone llama.cpp source
        run: |
          git clone --recursive --depth 1 https://github.com/ggml-org/llama.cpp.git llama_source

      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./llama_source 
          file: ./llama_source/.devops/intel.Dockerfile 
          target: server
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest-official-fp16
          build-args:
            GGML_SYCL_F16=ON
          cache-from: type=gha
          cache-to: type=gha,mode=min
